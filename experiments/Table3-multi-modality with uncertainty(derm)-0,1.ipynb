{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d53ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger,adjust_learning_rate,CreateLogger,create_cosine_learning_schedule,encode_test_label,set_seed\n",
    "from model import Resnet_with_uncertainty_derm#不确定度\n",
    "from dependency import *\n",
    "from torch import optim\n",
    "from torchcontrib.optim import SWA\n",
    "from dataloader import generate_dataloader\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad1b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_dataloader, model_name):\n",
    "    net.set_mode(\"train\")\n",
    "    train_loss = 0\n",
    "    train_dia_acc = 0\n",
    "    train_sps_acc = 0\n",
    "    for index,(clinic_image,derm_image,meta_data,label) in enumerate(train_dataloader):\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        clinic_image = clinic_image.cuda()\n",
    "        derm_image = derm_image.cuda()\n",
    "        #meta_data = meta_data.cuda()\n",
    "        \n",
    "        #Diagnostic label\n",
    "        diagnosis_label = label[0].long().cuda()\n",
    "        #Seven-Point Checklist labels\n",
    "        pn_label = label[1].long().cuda()\n",
    "        str_label = label[2].long().cuda()\n",
    "        pig_label = label[3].long().cuda()\n",
    "        rs_label = label[4].long().cuda()\n",
    "        dag_label = label[5].long().cuda()\n",
    "        bwv_label = label[6].long().cuda()\n",
    "        vs_label = label[7].long().cuda()\n",
    "        #uncertainty\n",
    "        \n",
    "        [(logit_diagnosis_derm,logit_pn_derm,logit_str_derm,logit_pig_derm,logit_rs_derm,logit_dag_derm,logit_bwv_derm,logit_vs_derm,logit_uncertainty_derm)] = net((derm_image))\n",
    "        \n",
    "        #derm\n",
    "        prediction1 = torch.argmax(torch.nn.Softmax(dim=1)(logit_diagnosis_derm),dim = 1)\n",
    "        \n",
    "        prediction2 = torch.argmax(torch.nn.Softmax(dim=1)(logit_pn_derm),dim = 1)\n",
    "\n",
    "        prediction3 = torch.argmax(torch.nn.Softmax(dim=1)(logit_str_derm),dim = 1)\n",
    "\n",
    "        prediction4 = torch.argmax(torch.nn.Softmax(dim=1)(logit_pig_derm), dim = 1)\n",
    "\n",
    "        prediction5 =torch.argmax(torch.nn.Softmax(dim=1)(logit_rs_derm), dim = 1)\n",
    "\n",
    "        prediction6 = torch.argmax(torch.nn.Softmax(dim=1)(logit_dag_derm), dim = 1)\n",
    "\n",
    "        prediction7 = torch.argmax(torch.nn.Softmax(dim=1)(logit_bwv_derm), dim = 1)\n",
    "\n",
    "        prediction8 = torch.argmax(torch.nn.Softmax(dim=1)(logit_vs_derm), dim = 1)\n",
    "\n",
    "        diagnosis_label_t = diagnosis_label.unsqueeze(0)\n",
    "        pn_label_t = pn_label.unsqueeze(0)\n",
    "        str_label_t = str_label.unsqueeze(0)\n",
    "        pig_label_t = pig_label.unsqueeze(0)\n",
    "        rs_label_t = rs_label.unsqueeze(0)\n",
    "        dag_label_t = dag_label.unsqueeze(0)\n",
    "        bwv_label_t = bwv_label.unsqueeze(0)\n",
    "        vs_label_t = vs_label.unsqueeze(0)\n",
    "            \n",
    "        #\n",
    "        pn_label_t = np.array(pn_label_t.cpu(),dtype=\"int\")\n",
    "        str_label_t = np.array(str_label_t.cpu(),dtype=\"int\")\n",
    "        pig_label_t = np.array(pig_label_t.cpu(),dtype=\"int\")\n",
    "        rs_label_t = np.array(rs_label_t.cpu(),dtype=\"int\")\n",
    "        dag_label_t = np.array(dag_label_t.cpu(),dtype=\"int\")\n",
    "        bwv_label_t = np.array(bwv_label_t.cpu(),dtype=\"int\")\n",
    "        vs_label_t = np.array(vs_label_t.cpu(),dtype=\"int\")\n",
    "        diagnosis_label_t = np.array(diagnosis_label_t.cpu(),dtype=\"int\")\n",
    "\n",
    "        t = np.hstack((diagnosis_label_t.T,pn_label_t.T))\n",
    "        t = np.hstack((t,str_label_t.T))\n",
    "        t = np.hstack((t,pig_label_t.T))\n",
    "        t = np.hstack((t,rs_label_t.T))\n",
    "        t = np.hstack((t,dag_label_t.T))\n",
    "        t = np.hstack((t,bwv_label_t.T))\n",
    "        t = np.hstack((t,vs_label_t.T))\n",
    "        t = torch.tensor(t)\n",
    "            \n",
    "        prediction1 = prediction1.unsqueeze(0)\n",
    "        prediction2 = prediction2.unsqueeze(0)\n",
    "        prediction3 = prediction3.unsqueeze(0)\n",
    "        prediction4 = prediction4.unsqueeze(0)\n",
    "        prediction5 = prediction5.unsqueeze(0)\n",
    "        prediction6 = prediction6.unsqueeze(0)\n",
    "        prediction7 = prediction7.unsqueeze(0)\n",
    "        prediction8 = prediction8.unsqueeze(0)\n",
    "        prediction1 = np.array(prediction1.cpu(),dtype=\"int\")\n",
    "        prediction2 = np.array(prediction2.cpu(),dtype=\"int\")\n",
    "        prediction3 = np.array(prediction3.cpu(),dtype=\"int\")\n",
    "        prediction4 = np.array(prediction4.cpu(),dtype=\"int\")\n",
    "        prediction5 = np.array(prediction5.cpu(),dtype=\"int\")\n",
    "        prediction6 = np.array(prediction6.cpu(),dtype=\"int\")\n",
    "        prediction7 = np.array(prediction7.cpu(),dtype=\"int\")\n",
    "        prediction8 = np.array(prediction8.cpu(),dtype=\"int\")\n",
    "        \n",
    "        p = np.hstack((prediction1.T,prediction2.T))\n",
    "        p = np.hstack((p,prediction3.T))\n",
    "        p = np.hstack((p,prediction4.T))\n",
    "        p = np.hstack((p,prediction5.T))\n",
    "        p = np.hstack((p,prediction6.T))\n",
    "        p = np.hstack((p,prediction7.T))\n",
    "        p = np.hstack((p,prediction8.T))\n",
    "        p = torch.tensor(p)\n",
    "        \n",
    "        certainty_b = (t == p).long()\n",
    "        certainty_ones = torch.tensor(np.ones(certainty_b.size()))\n",
    "        uncertainty_label_derm = []\n",
    "        for i in range(certainty_ones.size(0)):\n",
    "            mean_squared_error_tmp = mean_squared_error(certainty_ones[i,:],certainty_b[i,:])\n",
    "            if mean_squared_error_tmp >=0.6:\n",
    "                mean_squared_error_tmp = 1\n",
    "            else:\n",
    "                mean_squared_error_tmp = 0\n",
    "            uncertainty_label_derm.append([mean_squared_error_tmp]) # bigger uncertainty, bigger MSE, means the prediction is less accurate. \n",
    "        uncertainty_label_derm = torch.tensor(uncertainty_label_derm)\n",
    "        #uncertainty\n",
    "        uncertainty_label_derm = uncertainty_label_derm.float().cuda()\n",
    "        \n",
    "        loss_derm = torch.div(\n",
    "          net.criterion(logit_diagnosis_derm, diagnosis_label)\n",
    "        + net.criterion(logit_pn_derm, pn_label)\n",
    "        + net.criterion(logit_str_derm, str_label)\n",
    "        + net.criterion(logit_pig_derm, pig_label)\n",
    "        + net.criterion(logit_rs_derm, rs_label)\n",
    "        + net.criterion(logit_dag_derm, dag_label)\n",
    "        + net.criterion(logit_bwv_derm, bwv_label)\n",
    "        + net.criterion(logit_vs_derm, vs_label)\n",
    "        + net.criterion_MSE(logit_uncertainty_derm,uncertainty_label_derm), 9)\n",
    "        \n",
    "        loss = loss_derm \n",
    "        \n",
    "        dia_acc_all = torch.div(net.metric(logit_diagnosis_derm,diagnosis_label),int(derm_image.size(0)))\n",
    "        sps_acc_all = torch.div(  net.metric(logit_pn_derm,pn_label)\n",
    "                                + net.metric(logit_str_derm,str_label)\n",
    "                                + net.metric(logit_pig_derm,pig_label)\n",
    "                                + net.metric(logit_rs_derm,rs_label)\n",
    "                                + net.metric(logit_dag_derm,dag_label)\n",
    "                                + net.metric(logit_bwv_derm,bwv_label)\n",
    "                                + net.metric(logit_vs_derm,vs_label),int(7 * derm_image.size(0)))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_dia_acc += dia_acc_all.item()\n",
    "        train_sps_acc += sps_acc_all.item()\n",
    "\n",
    "    train_loss = train_loss / (index + 1) # Because the index start with the value 0f zero\n",
    "    train_dia_acc = train_dia_acc / (index + 1)\n",
    "    train_sps_acc = train_sps_acc / (index + 1)\n",
    "\n",
    "    return train_loss,train_dia_acc,train_sps_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee99567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(net,val_dataloader,model_name):\n",
    "    net.set_mode('valid')\n",
    "    val_loss = 0\n",
    "    val_dia_acc = 0\n",
    "    vaL_sps_acc = 0\n",
    "    for index, (clinic_image, derm_image, meta_data, label) in enumerate(val_dataloader):\n",
    "\n",
    "        clinic_image = clinic_image.cuda()\n",
    "        derm_image   = derm_image.cuda()\n",
    "        #meta_data    = meta_data.cuda()\n",
    "\n",
    "        diagnosis_label = label[0].long().cuda()\n",
    "        pn_label = label[1].long().cuda()\n",
    "        str_label = label[2].long().cuda()\n",
    "        pig_label = label[3].long().cuda()\n",
    "        rs_label = label[4].long().cuda()\n",
    "        dag_label = label[5].long().cuda()\n",
    "        bwv_label = label[6].long().cuda()\n",
    "        vs_label = label[7].long().cuda()\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            [(logit_diagnosis_derm,logit_pn_derm,logit_str_derm,logit_pig_derm,logit_rs_derm,logit_dag_derm,logit_bwv_derm,logit_vs_derm,logit_uncertainty_derm)] = net((derm_image))\n",
    "        \n",
    "            diagnosis_label_t = diagnosis_label.unsqueeze(0)\n",
    "            pn_label_t = pn_label.unsqueeze(0)\n",
    "            str_label_t = str_label.unsqueeze(0)\n",
    "            pig_label_t = pig_label.unsqueeze(0)\n",
    "            rs_label_t = rs_label.unsqueeze(0)\n",
    "            dag_label_t = dag_label.unsqueeze(0)\n",
    "            bwv_label_t = bwv_label.unsqueeze(0)\n",
    "            vs_label_t = vs_label.unsqueeze(0)\n",
    "        \n",
    "            #\n",
    "            pn_label_t = np.array(pn_label_t.cpu(),dtype=\"int\")\n",
    "            str_label_t = np.array(str_label_t.cpu(),dtype=\"int\")\n",
    "            pig_label_t = np.array(pig_label_t.cpu(),dtype=\"int\")\n",
    "            rs_label_t = np.array(rs_label_t.cpu(),dtype=\"int\")\n",
    "            dag_label_t = np.array(dag_label_t.cpu(),dtype=\"int\")\n",
    "            bwv_label_t = np.array(bwv_label_t.cpu(),dtype=\"int\")\n",
    "            vs_label_t = np.array(vs_label_t.cpu(),dtype=\"int\")\n",
    "            diagnosis_label_t = np.array(diagnosis_label_t.cpu(),dtype=\"int\")\n",
    "        \n",
    "            t = np.hstack((diagnosis_label_t.T,pn_label_t.T))\n",
    "            t = np.hstack((t,str_label_t.T))\n",
    "            t = np.hstack((t,pig_label_t.T))\n",
    "            t = np.hstack((t,rs_label_t.T))\n",
    "            t = np.hstack((t,dag_label_t.T))\n",
    "            t = np.hstack((t,bwv_label_t.T))\n",
    "            t = np.hstack((t,vs_label_t.T))\n",
    "            t = torch.tensor(t)\n",
    "         \n",
    "            #derm\n",
    "            prediction1 = torch.argmax(torch.nn.Softmax(dim=1)(logit_diagnosis_derm), dim = 1)\n",
    "        \n",
    "            prediction2 = torch.argmax(torch.nn.Softmax(dim=1)(logit_pn_derm), dim = 1)\n",
    "\n",
    "            prediction3 = torch.argmax(torch.nn.Softmax(dim=1)(logit_str_derm), dim = 1)\n",
    "\n",
    "            prediction4 = torch.argmax(torch.nn.Softmax(dim=1)(logit_pig_derm), dim = 1)\n",
    "\n",
    "            prediction5 = torch.argmax(torch.nn.Softmax(dim=1)(logit_rs_derm), dim = 1)\n",
    "\n",
    "            prediction6 = torch.argmax(torch.nn.Softmax(dim=1)(logit_dag_derm), dim = 1)\n",
    "    \n",
    "            prediction7 = torch.argmax(torch.nn.Softmax(dim=1)(logit_bwv_derm), dim = 1)\n",
    "\n",
    "            prediction8 = torch.argmax(torch.nn.Softmax(dim=1)(logit_vs_derm), dim = 1)\n",
    "\n",
    "            prediction1 = prediction1.unsqueeze(0)\n",
    "            prediction2 = prediction2.unsqueeze(0)\n",
    "            prediction3 = prediction3.unsqueeze(0)\n",
    "            prediction4 = prediction4.unsqueeze(0)\n",
    "            prediction5 = prediction5.unsqueeze(0)\n",
    "            prediction6 = prediction6.unsqueeze(0)\n",
    "            prediction7 = prediction7.unsqueeze(0)\n",
    "            prediction8 = prediction8.unsqueeze(0)\n",
    "            prediction1 = np.array(prediction1.cpu(),dtype=\"int\")\n",
    "            prediction2 = np.array(prediction2.cpu(),dtype=\"int\")\n",
    "            prediction3 = np.array(prediction3.cpu(),dtype=\"int\")\n",
    "            prediction4 = np.array(prediction4.cpu(),dtype=\"int\")\n",
    "            prediction5 = np.array(prediction5.cpu(),dtype=\"int\")\n",
    "            prediction6 = np.array(prediction6.cpu(),dtype=\"int\")\n",
    "            prediction7 = np.array(prediction7.cpu(),dtype=\"int\")\n",
    "            prediction8 = np.array(prediction8.cpu(),dtype=\"int\")\n",
    "        \n",
    "            p = np.hstack((prediction1.T,prediction2.T))\n",
    "            p = np.hstack((p,prediction3.T))\n",
    "            p = np.hstack((p,prediction4.T))\n",
    "            p = np.hstack((p,prediction5.T))\n",
    "            p = np.hstack((p,prediction6.T))\n",
    "            p = np.hstack((p,prediction7.T))\n",
    "            p = np.hstack((p,prediction8.T))\n",
    "            p = torch.tensor(p)\n",
    "        \n",
    "            certainty_b = (t == p).long()\n",
    "            certainty_ones = torch.tensor(np.ones(certainty_b.size()))\n",
    "            uncertainty_label_derm = []\n",
    "            for i in range(certainty_ones.size(0)):\n",
    "                mean_squared_error_tmp = mean_squared_error(certainty_ones[i,:],certainty_b[i,:])\n",
    "                if mean_squared_error_tmp >=0.6:\n",
    "                    mean_squared_error_tmp = 1\n",
    "                else:\n",
    "                    mean_squared_error_tmp = 0\n",
    "                uncertainty_label_derm.append([mean_squared_error_tmp]) # bigger uncertainty, bigger MSE, means the prediction is less accurate. \n",
    "            uncertainty_label_derm = torch.tensor(uncertainty_label_derm)\n",
    "            #uncertainty\n",
    "            uncertainty_label_derm = uncertainty_label_derm.float().cuda()\n",
    "        \n",
    "            loss_derm = torch.div(\n",
    "              net.criterion(logit_diagnosis_derm, diagnosis_label)\n",
    "            + net.criterion(logit_pn_derm, pn_label)\n",
    "            + net.criterion(logit_str_derm, str_label)\n",
    "            + net.criterion(logit_pig_derm, pig_label)\n",
    "            + net.criterion(logit_rs_derm, rs_label)\n",
    "            + net.criterion(logit_dag_derm, dag_label)\n",
    "            + net.criterion(logit_bwv_derm, bwv_label)\n",
    "            + net.criterion(logit_vs_derm, vs_label)\n",
    "            + net.criterion_MSE(logit_uncertainty_derm,uncertainty_label_derm), 9)\n",
    "\n",
    "            loss = loss_derm\n",
    "            \n",
    "            dia_acc_all = torch.div(net.metric(logit_diagnosis_derm,diagnosis_label),int(derm_image.size(0)))\n",
    "            sps_acc_all = torch.div(net.metric(logit_pn_derm,pn_label)\n",
    "                                + net.metric(logit_str_derm,str_label)\n",
    "                                + net.metric(logit_pig_derm,pig_label)\n",
    "                                + net.metric(logit_rs_derm,rs_label)\n",
    "                                + net.metric(logit_dag_derm,dag_label)\n",
    "                                + net.metric(logit_bwv_derm,bwv_label)\n",
    "                                + net.metric(logit_vs_derm,vs_label),int(7 * derm_image.size(0)))\n",
    "            \n",
    "                                    \n",
    "        val_loss += loss.item()\n",
    "        val_dia_acc += dia_acc_all.item()\n",
    "        vaL_sps_acc += sps_acc_all.item()\n",
    "\n",
    "    val_loss = val_loss / (index + 1)\n",
    "    val_dia_acc = val_dia_acc / (index + 1)\n",
    "    vaL_sps_acc = vaL_sps_acc / (index + 1)\n",
    "\n",
    "    return val_loss,val_dia_acc,vaL_sps_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27676b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model_name,mode,i):\n",
    "    log.write('** start Resnet_with_Uncertainty(derm) training here! **\\n')\n",
    "    #best_acc = 0\n",
    "    es = 0\n",
    "    patience = 50\n",
    "    best_mean_acc = 0 \n",
    "    best_loss = 300\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        swa_lr = cosine_learning_schedule[epoch]\n",
    "        adjust_learning_rate(opt, swa_lr)\n",
    "\n",
    "        # train_mode\n",
    "        train_loss,train_dia_acc,train_sps_acc=train(net, train_dataloader,model_name)\n",
    "        log.write('Round: {}, epoch: {}, Train Loss: {:.4f}, Train Dia Acc: {:.4f}, Train SPS Acc: {:.4f}\\n'.format(i, epoch, train_loss,\n",
    "                                                                                                         train_dia_acc,\n",
    "                                                                                                         train_sps_acc))\n",
    "\n",
    "        # validation mode\n",
    "        val_loss,val_dia_acc,val_sps_acc = validation(net, val_dataloader,model_name)\n",
    "        \n",
    "        val_acc = (val_dia_acc + val_sps_acc) / 2\n",
    "        val_mean_acc = (val_dia_acc*1 + val_sps_acc*7)/8\n",
    "        \n",
    "        log.write('Round: {}, epoch: {}, Valid Loss: {:.4f}, Valid Dia Acc: {:.4f}, Valid SPS Acc: {:.4f}\\n'.format(i, epoch, val_loss,\n",
    "                                                                                                         val_dia_acc,\n",
    "                                                                                                         val_sps_acc))\n",
    "\n",
    "     \n",
    "        if val_mean_acc > best_mean_acc:\n",
    "            es = 0\n",
    "            best_mean_acc = val_mean_acc\n",
    "            torch.save(net.state_dict(), out_dir + '/checkpoint/{}_model.pth'.format('best_mean_acc'))\n",
    "            log.write('Current Best Mean Acc is {}'.format(best_mean_acc))\n",
    "        #  else:\n",
    "        #      es += 1\n",
    "        #      print(\"Counter {} of {}\".format(es,patience))\n",
    "          \n",
    "        #      if es > patience:\n",
    "        #          print(\"Early stopping with best_mean_acc: {:.4f}\".format(best_mean_acc), \"and val_mean_acc for this epoch: {:.4f}\".format(val_mean_acc))\n",
    "        #          break\n",
    "  \n",
    "  \n",
    "        if epoch > (epochs - swa_epoch) and epoch % 1 == 0:\n",
    "            opt.update_swa()\n",
    "            log.write('SWA Epoch: {}'.format(epoch))\n",
    "\n",
    "    torch.save(net.state_dict(), out_dir+'/swa_{}_resnet50_model.pth'.format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cd46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "\n",
      "--- [START IDENTIFIER] ----------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tout_dir      = ./multimodal_Resnet_derm_Normal_weight_file/0/\n",
      "\n",
      "\n",
      "\n",
      "\t<additional comments> ...  \n",
      "\n",
      "\t  - multimodal Resnet_derm  \n",
      "\n",
      "\t  - simple augmentation \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Hyperparameters\n",
    "    mode = 'multimodal'\n",
    "    tech = \"derm\"\n",
    "    model_name = str('Resnet')+str(\"_\")+str(tech)\n",
    "    shape = (229, 229)\n",
    "    batch_size = 5\n",
    "    num_workers = 0\n",
    "    data_mode = 'Normal'\n",
    "    deterministic = True\n",
    "    if deterministic:\n",
    "        if data_mode == 'Normal':\n",
    "            random_seeds = 170\n",
    "        elif data_mode == 'self_evaluated':\n",
    "            random_seeds = 183\n",
    "    rounds = 1\n",
    "    lr = 4.9e-5##\n",
    "    epochs = 250\n",
    "    swa_epoch = 150\n",
    "\n",
    "    train_dataloader, val_dataloader = generate_dataloader(shape, batch_size, num_workers, data_mode,\"concat\")\n",
    "    \n",
    "    for i in range(rounds):\n",
    "        if deterministic:\n",
    "            set_seed(random_seeds + i)\n",
    "      # create logger\n",
    "        print(random_seeds+i)\n",
    "        log, out_dir = CreateLogger(mode, model_name,i,data_mode)\n",
    "        #network \n",
    "        net = Resnet_with_uncertainty_derm(class_list).cuda()\n",
    "        #net = FusionNet(class_list).to(device)\n",
    "      # create optimizer\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr,weight_decay=5e-5)   #weight_decay   #5e-5\n",
    "        opt = SWA(optimizer)  \n",
    "      # create learning schedule\n",
    "        cosine_learning_schedule = create_cosine_learning_schedule(epochs, lr)\n",
    "        run_train(model_name,mode,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3143a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
